[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch=64
subdivisions=4
width=512
height=320
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.8
exposure = 2.3
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 10000
policy=steps
#steps=400000,450000
#scales=.1,.1
steps=2000,4000,5000,7500,10000
scales=.1,.1,.1,.1,.1



[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=13
activation=linear



[yolo]
mask = 5
anchors = 9, 10,  13, 14,  18, 19,  25, 26,  40, 40,  60, 60
classes=8
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 8

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=65
activation=linear



[yolo]
mask = 0,1,2,3,4
anchors = 9, 10,  13, 14,  18, 19,  25, 26,  40, 40,  60, 60
classes=8
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
